# -*- coding: utf-8 -*-
"""MNIST_hand_digit_recognition-Convolutional_Neural_Network_(CNN)_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17L2ml3x74gouvzCIxHdQynGWRLwrq_9f

# MNIST Hand Digit Recognition - using Keras Convolutional Neural Network Model
"""

import tensorflow as tf 
import numpy as np
import keras
import matplotlib.pyplot as plt
import seaborn as sns
from keras.models import Sequential
from keras.layers import Dense, Activation, Flatten
from keras.layers.convolutional import Conv2D, MaxPooling2D
from sklearn.metrics import confusion_matrix

# %matplotlib inline

# Load MNIST hand digit recognition dataset
mnist = tf.keras.datasets.mnist

# Normalization of features
(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train/255.0, x_test/255.0

tf.keras.backend.image_data_format()

# Show first 4 hand digit recognition data
print('First 4 hand digit training examples:')
plt.subplot(221)
plt.imshow(x_train[0], cmap='gray')
plt.subplot(222)
plt.imshow(x_train[1], cmap='gray')
plt.subplot(223)
plt.imshow(x_train[2], cmap='gray')
plt.subplot(224)
plt.imshow(x_train[3], cmap='gray')
plt.show()

print('Corresponding output labels: ', y_train[0:4])

# Training dataset information
x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)
x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)
print('Shape of training feature example: ', x_train[0].shape)
print('Shape of training examples: ', x_train.shape)
print('Number of training examples: ', len(x_train))
print('Shape of training labels: ', y_train.shape)
print('Number of training labels: ', len(y_train))

# Testing dataset information
print('Testing examples shape: ', x_test.shape)
print('Number of testing examples: ', len(x_test))
print('Testing labels shape: ', y_test.shape)
print('Number of testing lables: ', len(y_test))

# One hot encoding training labels 
one_hot_labels = tf.keras.utils.to_categorical(y_train, num_classes=10)
one_hot_labels

# Build CNN model
def build_model():
  '''
  Builds CNN model
  
  Returns:
  model -- 
  '''

  model = Sequential()
  model.add(Conv2D(16, (3, 3), input_shape=(28, 28, 1)))
  model.add(Activation('relu'))
  model.add(MaxPooling2D(pool_size=(2, 2)))
  model.add(Conv2D(32, (3, 3)))
  model.add(Activation('relu'))
  model.add(MaxPooling2D(pool_size=(2, 2)))
  model.add(Conv2D(64, (3, 3)))
  model.add(Activation('relu'))
  model.add(Flatten())
  model.add(Dense(128))
  model.add(Activation('relu'))
  model.add(Dense(10, activation='softmax'))

  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
  
  return model

"""# Fit the CNN model without validation set"""

# model summary 
model_1 = build_model()
print(model_1.summary())

# fit the model without validation set
history_wo_val_set = model_1.fit(x_train, one_hot_labels, epochs=10, batch_size=500, verbose=1)

"""# Fit CNN model with validation set"""

# fit the model with validation set
model_2 = build_model()
history_w_val_set = model_2.fit(x_train, one_hot_labels, epochs=10, validation_split=0.2, batch_size=500, verbose=1)

"""# Plot training and validation errors"""

# Train test plot for model without validation set
def plot_history(history):
  '''
  Plots train validation set error and accuracy
  
  Arguments:
  history -- model history
  '''
  
  plt.subplot(211)
  plt.plot(history.epoch, np.array(history.history['loss']), label='Train Loss')
  if 'val_loss' in history.history:
    plt.plot(history.epoch, np.array(history.history['val_loss']), label='Val Loss')
  plt.xlabel('Epoch')
  plt.ylabel('Loss')
  plt.legend()

  plt.subplot(212)
  plt.plot(history.epoch, np.array(history.history['acc']), label='Train Acc')
  if 'val_loss' in history.history:
    plt.plot(history.epoch, np.array(history.history['val_acc']), label='Val Acc')
  plt.xlabel('Epoch')
  plt.ylabel('Accuracy')
  plt.legend()

  plt.show()

# plot
plot_history(history_wo_val_set)

# plot
plot_history(history_w_val_set)

"""# Model Analysis"""

# Model analysis - Prediction and confusion matrix
def model_analysis(model, x_test, y_test):
  '''
  Result analysis
  
  Arguments:
  model -- keras model
  x_test -- 
  y_test -- 
  
  '''
  
  # Model predict labels
  y_predicted = model.predict(x_test)
  
  # Invert one-hot-encoded values
  y_predicted = np.argmax(y_predicted, axis=1)
  
  print('True Labels: ', y_test)
  print('Predicted Labels: ', y_predicted)
  print()
  
  # Evaluate the model - loss value and metric (accuracy) value
  one_hot_encode_test_label = tf.keras.utils.to_categorical(y_test, num_classes=10)
  scores = model.evaluate(x_test, one_hot_encode_test_label, verbose=0)
  print("Test Error: %.2f%%" % (scores[0]*100))
  print("Test Accuracy: %.2f%%" % (scores[1]*100))
  print()

  # Confusion matrix
  cmap = plt.cm.Blues
  cm = confusion_matrix(y_test, y_predicted)
  plt.figure(figsize=(12,12))
  plt.title('MNIST Hand Digit Recognition Dataset', fontsize=24)
  sns.heatmap(cm, annot=True, fmt='d', annot_kws={"size": 12}, cmap='Blues')
  plt.xlabel('True Labels', fontsize=20)
  plt.ylabel('Predicted Labels', fontsize=20)
  plt.show()

# Analysis of model without validation set
model_analysis(model_1, x_test, y_test)

# Analysis of model with validation set
model_analysis(model_2, x_test, y_test)

